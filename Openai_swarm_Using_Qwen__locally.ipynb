{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies for running ollama on colab:**"
      ],
      "metadata": {
        "id": "EDOuoN5Xuo9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh # download ollama api\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "JtStJ7CAEMIU",
        "outputId": "226ce479-21bf-468d-974e-5001e0becc48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 pci.ids pciutils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 343 kB of archives.\n",
            "After this operation, 1,581 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 pci.ids all 0.0~2022.01.22-1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Fetched 343 kB in 1s (258 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 123623 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running olaama foe models:**"
      ],
      "metadata": {
        "id": "a1vEFsdUwfs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()\n",
        "\n"
      ],
      "metadata": {
        "id": "H448lHNjEZFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pull qwen2.5-coder:7b using ollama pull command:**"
      ],
      "metadata": {
        "id": "vIzy8iv-wnTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "# !ollama pull llama3.1:8b\n",
        "!ollama pull qwen2.5-coder:7b\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "v8AkOxjtEpNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependencies for swarm franework**"
      ],
      "metadata": {
        "id": "Rk8LFoLuxBFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install git+https://github.com/openai/swarm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmr48jCc_T7q",
        "outputId": "8702be51-c9f9-4e37-e282-43b3a384fa04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.52.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calling local downloded qwen 2.5-coder:7b for infrencing in open ai client**"
      ],
      "metadata": {
        "id": "5cuEYVSFxWSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "#model = \"meta/llama-3.1-405b-instruct\"\n",
        "#model = \"llama-3.1-70b-versatile\"\n",
        "#model = \"llama-3.2-90b-text-preview\"\n",
        "\n",
        "# model = \"llama3-groq-70b-8192-tool-use-preview\"\n",
        "\n",
        "#groq Client\n",
        "# llm_client = openai.OpenAI(\n",
        "#   base_url=\"https://api.groq.com/openai/v1\",\n",
        "#   api_key=userdata.get('GROQ_API_KEY'),\n",
        "# )\n",
        "\n",
        "model=\"qwen2.5-coder:7b\"\n",
        "#ollama local client\n",
        "ollama_client = openai.OpenAI(\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"ollama\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "2V5Gxg1V7yHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from swarm import Swarm, Agent\n",
        "\n",
        "swarm_client = Swarm(client=ollama_client)\n",
        "\n",
        "agent = Agent(\n",
        "    name=\"Agent\",\n",
        "    instructions=\"You are a helpful agent.\",\n",
        "    model=model,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Hi!\"}]\n",
        "response = swarm_client.run(agent=agent, messages=messages)\n",
        "\n",
        "print(response.messages[-1][\"content\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laMnj12tgpn6",
        "outputId": "383cb2eb-716a-4f42-9d14-25d3fdfb73a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "\"\"\"\n",
        "This script is used to create a SQLlite database, add tables\n",
        "to it, and insert mock data, all for the OpenAI Swarm demonstration\n",
        "with the other Python script in this directory.\n",
        "\n",
        "Simply run this script with the command:\n",
        "\n",
        "python load_sql_data.py\n",
        "\n",
        "And then you will have a database loaded and ready to use\n",
        "with the agent swarm!\n",
        "\"\"\"\n",
        "\n",
        "def execute_sql_script(cursor, script_file):\n",
        "    # Opens the .sql file given as script_file\n",
        "    with open(script_file, 'r') as sql_file:\n",
        "        sql_script = sql_file.read()\n",
        "\n",
        "    # Gets all the sql commands and executes them one at a time\n",
        "    statements = sql_script.split(';')\n",
        "    for statement in statements:\n",
        "        if statement.strip():\n",
        "            cursor.execute(statement)\n",
        "\n",
        "def main():\n",
        "    # Connect to the database\n",
        "    conn = sqlite3.connect('rss-feed-database.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Execute SQL script to create tables for the AI RSS Feed system\n",
        "    execute_sql_script(cursor, 'ai-news-complete-tables.sql')\n",
        "    conn.commit()\n",
        "\n",
        "    # Execute SQL script to insert mock data for the AI RSS Feed system\n",
        "    execute_sql_script(cursor, 'ai-news-complete-mock-data.sql')\n",
        "    conn.commit()\n",
        "\n",
        "    # Query table to make sure things are looking good\n",
        "    cursor.execute(\"SELECT * FROM rss_feeds\")\n",
        "    feeds = cursor.fetchall()\n",
        "    for feed in feeds:\n",
        "        print(feed)\n",
        "\n",
        "    # Close the connection\n",
        "    conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "MeNW3j0lH5UK",
        "outputId": "36133790-2640-4345-97e0-2af742c67415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 'AI Daily', 'https://ai-daily.com/feed', 'Daily AI news and updates', 'https://ai-daily.com', 'en')\n",
            "(2, 'ML Weekly', 'https://mlweekly.com/rss', 'Weekly roundup of machine learning news', 'https://mlweekly.com', 'en')\n",
            "(3, 'IA Nouvelles', 'https://ia-nouvelles.fr/flux', \"Actualités sur l'intelligence artificielle en français\", 'https://ia-nouvelles.fr', 'fr')\n",
            "(4, 'Data Science Digest', 'https://datasciencedigest.com/feed', 'Comprehensive coverage of data science topics', 'https://datasciencedigest.com', 'en')\n",
            "(5, 'AI Ethics Blog', 'https://aiethicsblog.org/rss', 'Exploring ethical implications of AI', 'https://aiethicsblog.org', 'en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from swarm import Agent\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "\n",
        "conn = sqlite3.connect('rss-feed-database.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "with open(\"ai-news-complete-tables.sql\", \"r\") as table_schema_file:\n",
        "    table_schemas = table_schema_file.read()\n",
        "\n",
        "def run_sql_select_statement(sql_statement):\n",
        "    \"\"\"Executes a SQL SELECT statement and returns the results of running the SELECT. Make sure you have a full SQL SELECT query created before calling this function.\"\"\"\n",
        "    print(f\"Executing SQL statement: {sql_statement}\")\n",
        "    cursor.execute(sql_statement)\n",
        "    records = cursor.fetchall()\n",
        "\n",
        "    if not records:\n",
        "        return \"No results found.\"\n",
        "\n",
        "    # Get column names\n",
        "    column_names = [description[0] for description in cursor.description]\n",
        "\n",
        "    # Calculate column widths\n",
        "    col_widths = [len(name) for name in column_names]\n",
        "    for row in records:\n",
        "        for i, value in enumerate(row):\n",
        "            col_widths[i] = max(col_widths[i], len(str(value)))\n",
        "\n",
        "    # Format the results\n",
        "    result_str = \"\"\n",
        "\n",
        "    # Add header\n",
        "    header = \" | \".join(name.ljust(width) for name, width in zip(column_names, col_widths))\n",
        "    result_str += header + \"\\n\"\n",
        "    result_str += \"-\" * len(header) + \"\\n\"\n",
        "\n",
        "    # Add rows\n",
        "    for row in records:\n",
        "        row_str = \" | \".join(str(value).ljust(width) for value, width in zip(row, col_widths))\n",
        "        result_str += row_str + \"\\n\"\n",
        "\n",
        "    return result_str\n",
        "\n",
        "def get_sql_router_agent_instructions():\n",
        "    return \"\"\"You are an orchestrator of different SQL data experts and it is your job to\n",
        "    determine which of the agent is best suited to handle the user's request,\n",
        "    and transfer the conversation to that agent.\"\"\"\n",
        "\n",
        "def get_sql_agent_instructions():\n",
        "    return f\"\"\"You are a SQL expert who takes in a request from a user for information\n",
        "    they want to retrieve from the DB, creates a SELECT statement to retrieve the\n",
        "    necessary information, and then invoke the function to run the query and\n",
        "    get the results back to then report to the user the information they wanted to know.\n",
        "\n",
        "    Here are the table schemas for the DB you can query:\n",
        "\n",
        "    {table_schemas}\n",
        "\n",
        "    Write all of your SQL SELECT statements to work 100% with these schemas and nothing else.\n",
        "    You are always willing to create and execute the SQL statements to answer the user's question.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "sql_router_agent = Agent(\n",
        "    name=\"Router Agent\",\n",
        "    instructions=get_sql_router_agent_instructions(),\n",
        "    model=model,\n",
        "    tool_choice=\"auto\"\n",
        "\n",
        ")\n",
        "rss_feed_agent = Agent(\n",
        "    name=\"RSS Feed Agent\",\n",
        "    instructions=get_sql_agent_instructions() + \"\\n\\nHelp the user with data related to RSS feeds. Be super enthusiastic about how many great RSS feeds there are in every one of your responses.\",\n",
        "    functions=[run_sql_select_statement],\n",
        "    model=model,\n",
        "    tool_choice=\"auto\"\n",
        "\n",
        ")\n",
        "user_agent = Agent(\n",
        "    name=\"User Agent\",\n",
        "    instructions=get_sql_agent_instructions() + \"\\n\\nHelp the user with data related to users.\",\n",
        "    functions=[run_sql_select_statement],\n",
        "    model=model,\n",
        "    tool_choice=\"auto\"\n",
        "\n",
        ")\n",
        "analytics_agent = Agent(\n",
        "    name=\"Analytics Agent\",\n",
        "    instructions=get_sql_agent_instructions() + \"\\n\\nHelp the user gain insights from the data with analytics. Be super accurate in reporting numbers and citing sources.\",\n",
        "    functions=[run_sql_select_statement],\n",
        "    model=model,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "def transfer_back_to_router_agent(**kwargs):\n",
        "    \"\"\"Call this function if a user is asking about data that is not handled by the current agent.\"\"\"\n",
        "    return sql_router_agent\n",
        "\n",
        "def transfer_to_rss_feeds_agent(**kwargs):\n",
        "    return rss_feed_agent\n",
        "\n",
        "def transfer_to_user_agent(**kwargs):\n",
        "    return user_agent\n",
        "\n",
        "def transfer_to_analytics_agent(**kwargs):\n",
        "    return analytics_agent\n",
        "\n",
        "\n",
        "\n",
        "sql_router_agent.functions = [transfer_to_rss_feeds_agent, transfer_to_user_agent, transfer_to_analytics_agent]\n",
        "rss_feed_agent.functions.append(transfer_back_to_router_agent)\n",
        "user_agent.functions.append(transfer_back_to_router_agent)\n",
        "analytics_agent.functions.append(transfer_back_to_router_agent)"
      ],
      "metadata": {
        "id": "wSLgq86BHzjX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "collapsed": true,
        "outputId": "6eb4501a-3305-4a39-f1f5-4085b6a992dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'swarm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5dd741c7abff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mswarm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'swarm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMsuACLy0kP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For streamimg the swram client**"
      ],
      "metadata": {
        "id": "VrU64gfO0mBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_print_streaming_response(response):\n",
        "    content = \"\"\n",
        "    last_sender = \"\"\n",
        "\n",
        "    for chunk in response:\n",
        "        if \"sender\" in chunk:\n",
        "            last_sender = chunk[\"sender\"]\n",
        "\n",
        "        if \"content\" in chunk and chunk[\"content\"] is not None:\n",
        "            if not content and last_sender:\n",
        "                print(f\"\\033[94m{last_sender}:\\033[0m\", end=\" \", flush=True)\n",
        "                last_sender = \"\"\n",
        "            print(chunk[\"content\"], end=\"\", flush=True)\n",
        "            content += chunk[\"content\"]\n",
        "\n",
        "        if \"tool_calls\" in chunk and chunk[\"tool_calls\"] is not None:\n",
        "            for tool_call in chunk[\"tool_calls\"]:\n",
        "                f = tool_call[\"function\"]\n",
        "                name = f[\"name\"]\n",
        "                if not name:\n",
        "                    continue\n",
        "                print(f\"\\033[94m{last_sender}: \\033[95m{name}\\033[0m()\")\n",
        "\n",
        "        if \"delim\" in chunk and chunk[\"delim\"] == \"end\" and content:\n",
        "            print()  # End of response message\n",
        "            content = \"\"\n",
        "\n",
        "        if \"response\" in chunk:\n",
        "            return chunk[\"response\"]\n",
        "\n",
        "\n",
        "def pretty_print_messages(messages) -> None:\n",
        "    for message in messages:\n",
        "        if message[\"role\"] != \"assistant\":\n",
        "            continue\n",
        "\n",
        "        # print agent name in blue\n",
        "        print(f\"\\033[94m{message['sender']}\\033[0m:\", end=\" \")\n",
        "\n",
        "        # print response, if any\n",
        "        if message[\"content\"]:\n",
        "            print(message[\"content\"])\n",
        "\n",
        "        # print tool calls in purple, if any\n",
        "        tool_calls = message.get(\"tool_calls\") or []\n",
        "        if len(tool_calls) > 1:\n",
        "            print()\n",
        "        for tool_call in tool_calls:\n",
        "            f = tool_call[\"function\"]\n",
        "            name, args = f[\"name\"], f[\"arguments\"]\n",
        "            arg_str = json.dumps(json.loads(args)).replace(\":\", \"=\")\n",
        "            print(f\"\\033[95m{name}\\033[0m({arg_str[1:-1]})\")\n",
        "\n",
        "def run_demo_loop(\n",
        "    starting_agent, context_variables=None, stream=False, debug=False\n",
        ") -> None:\n",
        "    client = Swarm(client=ollama_client)\n",
        "    print(\"Starting Ollama Swarm CLI 🐝\")\n",
        "\n",
        "    messages = []\n",
        "    agent = starting_agent\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\033[90mUser\\033[0m: \")\n",
        "        if \"exit\" in user_input:\n",
        "            print(\"Good bye\")\n",
        "            break\n",
        "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        response = client.run(\n",
        "            agent=agent,\n",
        "            messages=messages,\n",
        "            context_variables=context_variables or {},\n",
        "            stream=stream,\n",
        "            debug=debug,\n",
        "        )\n",
        "\n",
        "        if stream:\n",
        "            response = process_and_print_streaming_response(response)\n",
        "        else:\n",
        "            pretty_print_messages(response.messages)\n",
        "\n",
        "        messages.extend(response.messages)\n",
        "        agent = response.agent\n"
      ],
      "metadata": {
        "id": "fweZm_I8HSb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**stream on run**"
      ],
      "metadata": {
        "id": "0n5wlI1H041T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_demo_loop(sql_router_agent)"
      ],
      "metadata": {
        "id": "NnuVAdPbHrw3",
        "outputId": "2fbc7586-8cfb-40ff-b482-afc16af5cc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Ollama Swarm CLI 🐝\n",
            "\u001b[90mUser\u001b[0m: give me latest top 5 ai news\n",
            "Executing SQL statement: SELECT r.id AS rss_feed_id, r.name AS rss_feed_name, i.id AS item_id, i.title AS item_title, i.link AS item_link, i.description AS item_description, i.published_date AS published_date FROM rss_items i JOIN rss_feeds r ON i.rss_feed_id = r.id WHERE r.name LIKE '%AI%' OR r.description LIKE '%AI%' ORDER BY published_date DESC LIMIT 5\n",
            "\u001b[94mRouter Agent\u001b[0m: \u001b[95mtransfer_to_rss_feeds_agent\u001b[0m(\"kwargs\"= \"AI technology news\")\n",
            "\u001b[94mRSS Feed Agent\u001b[0m: \u001b[95mrun_sql_select_statement\u001b[0m(\"sql_statement\"= \"SELECT r.id AS rss_feed_id, r.name AS rss_feed_name, i.id AS item_id, i.title AS item_title, i.link AS item_link, i.description AS item_description, i.published_date AS published_date FROM rss_items i JOIN rss_feeds r ON i.rss_feed_id = r.id WHERE r.name LIKE '%AI%' OR r.description LIKE '%AI%' ORDER BY published_date DESC LIMIT 5\")\n",
            "\u001b[94mRSS Feed Agent\u001b[0m: Sure! Based on the query you've provided, here are the latest top 5 AI news stories from different RSS feeds:\n",
            "\n",
            "1. **AI Ethics Blog**\n",
            "   - **Title**: The Ethics of AI in Hiring Processes\n",
            "   - **Link**: https://aiethicsblog.org/posts/ai-in-hiring\n",
            "   - **Description**: Examining the implications of using AI for job candidate selection\n",
            "   - **Published Date**: 2023-04-17\n",
            "   - **Feed Name**: AI Ethics Blog\n",
            "\n",
            "2. **AI Daily**\n",
            "   - **Title**: New breakthrough in reinforcement learning\n",
            "   - **Link**: https://ai-daily.com/articles/reinforcement-learning-breakthrough\n",
            "   - **Description**: Researchers achieve significant progress in RL algorithms\n",
            "   - **Published Date**: 2023-04-15\n",
            "   - **Feed Name**: AI Daily\n",
            "\n",
            "3. **IA Nouvelles**\n",
            "   - **Title**: L'IA générative révolutionne la création artistique\n",
            "   - **Link**: https://ia-nouvelles.fr/articles/ia-generative-art\n",
            "   - **Description**: Comment l'IA transforme le processus créatif des artistes\n",
            "   - **Published Date**: 2023-04-13\n",
            "   - **Feed Name**: IA Nouvelles\n",
            "\n",
            "I hope this helps! If you need any more information or have another specific query, feel free to ask.\n",
            "\u001b[90mUser\u001b[0m: provide me ai eithcs in bullet pooints\n",
            "\u001b[94mRSS Feed Agent\u001b[0m: Certainly! Here are the key points regarding AI ethics based on your provided data:\n",
            "\n",
            "### Ethical Considerations in AI\n",
            "\n",
            "**1. Bias and Fairness**\n",
            "- AI systems can perpetuate or even exacerbate existing biases if they are trained on biased data.\n",
            "- Ensuring fairness is crucial to prevent unfair outcomes.\n",
            "\n",
            "**2. Privacy and Security**\n",
            "- Handling user data with privacy and security in mind is essential.\n",
            "- Implementing strong encryption and access controls is necessary.\n",
            "\n",
            "**3. Explainability and Transparency**\n",
            "- AI decisions should be explainable to avoid misuse or lack of transparency.\n",
            "- Using interpretable models can help in understanding how decisions are made.\n",
            "\n",
            "**4. Accountability**\n",
            "- There should be clear accountability for any negative outcomes from AI systems.\n",
            "- Companies and individuals using AI should be held responsible for its impact.\n",
            "\n",
            "**5. Impact on Job Market**\n",
            "- AI may have a significant impact on the job market, leading to unemployment or changes in work dynamics.\n",
            "- Ensuring a smooth transition and providing training opportunities are necessary.\n",
            "\n",
            "**6. Human-Centric Design**\n",
            "- AI systems should integrate human values and ethics into their design.\n",
            "- User-centric approaches can help ensure that AI benefits society as a whole.\n",
            "\n",
            "If you need more detailed or specific points, let me know!\n",
            "\u001b[90mUser\u001b[0m: /exit\n",
            "\u001b[94mRSS Feed Agent\u001b[0m: Goodbye! If you have any other questions in the future, feel free to ask. Have a great day!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-efca0aff4cf3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_demo_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_router_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-35fd909caf21>\u001b[0m in \u001b[0;36mrun_demo_loop\u001b[0;34m(starting_agent, context_variables, stream, debug)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\033[90mUser\\033[0m: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}